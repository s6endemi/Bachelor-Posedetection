\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=2.5cm]{geometry}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{float}
\usepackage{colortbl}

\definecolor{bestcolor}{RGB}{200, 230, 200}
\definecolor{highlight}{RGB}{255, 255, 200}

\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0.5em}

\title{\textbf{Thesis Status Report}\\[0.3em]\large Pose Estimation Evaluation for Home-Based Rehabilitation}
\author{}
\date{January 2026}

\begin{document}
\maketitle

%==============================================================================
\section*{Executive Summary}
%==============================================================================

\begin{table}[H]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Aspect} & \textbf{Status/Result} \\
\midrule
Data & 363,529 frames from 126 videos, MoCap ground truth \\
Models & MediaPipe, MoveNet, YOLOv8-Pose (all mobile-optimized) \\
\midrule
Accuracy & MediaPipe $\approx$ MoveNet (not significant, $p=0.098$) \\
Rotation Robustness & MediaPipe best (+31\% vs +54\% degradation) \\
Multi-Person Robustness & MediaPipe 2x better (torso vs bbox selection) \\
Temporal Stability & MoveNet best (42\% less jitter than MediaPipe) \\
\midrule
\rowcolor{highlight}
\textbf{Main Finding} & \textbf{No model dominates -- trade-offs depend on scenario} \\
\bottomrule
\end{tabular}
\end{table}


%==============================================================================
\section{Background \& Dataset}
%==============================================================================

\subsection{Context}
\textbf{Problem:} Patients doing physiotherapy exercises at home need real-time feedback on their movement quality. Smartphones can provide this using pose estimation -- but which model works best when users don't position themselves optimally?

\textbf{Research Goal:} Evaluate mobile pose estimation models for home-based rehabilitation, focusing on accuracy under realistic (suboptimal) conditions.

\subsection{Dataset: REHAB24-6}

\begin{table}[H]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
Property & Value \\
\midrule
Videos & 126 (21 patients $\times$ 6 exercises $\times$ 2 cameras) \\
Frames Analyzed & 363,529 \\
Cameras & c17 (frontal, 0--70°), c18 (lateral, 20--90°) \\
Ground Truth & Optical motion capture \\
Patient Type & Real rehabilitation patients \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Why this dataset?} One of few publicly available datasets with real clinical physiotherapy data and high-quality motion capture ground truth.

\textbf{Limitation:} The dataset was designed for exercise recognition, not specifically for pose estimation analysis. This affects:
\begin{itemize}[nosep]
    \item \textbf{Rotation:} Bimodal distribution (41\% frontal, 41\% lateral, only 18\% in between)
    \item \textbf{Multi-person:} Only 5 videos with permanent coach, ~30 with sporadic appearances
\end{itemize}

These aren't flaws -- the dataset serves its intended purpose well. It means my original narrow focus (rotation effects) evolved into a broader evaluation.

%==============================================================================
\section{Models Evaluated}
%==============================================================================

\begin{table}[H]
\centering
\begin{tabular}{@{}llll@{}}
\toprule
Model & Developer & Keypoints & Person Selection \\
\midrule
MediaPipe Pose & Google & 33 & Torso size \\
MoveNet MultiPose & Google/TensorFlow & 17 & Bounding box area \\
YOLOv8-Pose Nano & Ultralytics & 17 & Bounding box area \\
\bottomrule
\end{tabular}
\end{table}

All models are optimized for mobile/real-time use. Evaluation uses 12 comparable joints (shoulders, elbows, wrists, hips, knees, ankles).

\textbf{Metric: NMPJPE} (Normalized Mean Per Joint Position Error)
\begin{itemize}[nosep]
    \item Error normalized to torso length (comparable across body sizes)
    \item 10\% NMPJPE $\approx$ 5cm error per joint (assuming 50cm torso)
    \item $>$100\% NMPJPE indicates model tracked wrong person (``person switch'')
\end{itemize}

\textbf{Confidence Thresholds} (for reproducibility):
\begin{itemize}[nosep]
    \item MediaPipe: 0.1 detection threshold (default 0.5 caused 29\% failures)
    \item MoveNet: 0.1 score threshold
    \item YOLO: 0.3 joint confidence
\end{itemize}

%==============================================================================
\section{Results}
%==============================================================================

\subsection{Accuracy}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Model & Mean NMPJPE & Median NMPJPE & Std \\
\midrule
MoveNet & 11.5\% & 10.4\% & 5.5\% \\
MediaPipe & 12.5\% & 11.2\% & 7.2\% \\
YOLO & 12.9\% & 11.3\% & 6.8\% \\
\midrule
\multicolumn{4}{l}{\small MediaPipe vs MoveNet: $p=0.098$ (\textbf{not significant}), Cohen's $d=0.009$} \\
\bottomrule
\end{tabular}
\caption{Accuracy results (clean data, outliers removed). MediaPipe and MoveNet are statistically equivalent.}
\end{table}

\textbf{Camera effect (c17 vs c18):} The frontal camera (c17) has \textbf{10x more person-switch frames} than the lateral camera (c18). This is due to therapists/other people appearing more often in frontal view. After removing these outliers, c17 (frontal) is actually 1--2\% \textit{better} than c18 (lateral).

\subsection{Rotation Robustness}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Model & Frontal (0--20°) & Lateral (80--90°) & Relative Increase \\
\midrule
\rowcolor{bestcolor}
\textbf{MediaPipe} & 10.2\% & 13.3\% & \textbf{+31\%} \\
MoveNet & 9.0\% & 13.8\% & +54\% \\
YOLO & 9.4\% & 14.9\% & +58\% \\
\bottomrule
\end{tabular}
\caption{MediaPipe is most robust to viewpoint changes.}
\end{table}

\subsection{Multi-Person Robustness (Selection Strategy)}

\begin{table}[H]
\centering
\begin{tabular}{@{}lcccc@{}}
\toprule
Model & Selection & Clean Mean & Coach Mean & Increase \\
\midrule
\rowcolor{bestcolor}
\textbf{MediaPipe} & Torso size & 14.5\% & 44.8\% & \textbf{+209\%} \\
MoveNet & BBox area & 14.8\% & 64.9\% & +340\% \\
YOLO & BBox area & 17.7\% & 66.1\% & +274\% \\
\bottomrule
\end{tabular}
\caption{MediaPipe's torso-based selection is $\sim$2x more robust. (N=5 coach videos)}
\end{table}

\textbf{Why torso selection works better:} Torso size (shoulder-to-hip distance) correlates with camera distance. Bounding box area measures ``spread'' (arm position), not actual proximity.

\subsection{Temporal Stability (Jitter)}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Model & Mean Jitter & Median Jitter & Interpretation \\
\midrule
\rowcolor{bestcolor}
\textbf{MoveNet} & \textbf{1.06\%} & 0.42\% & Most stable \\
YOLO & 1.12\% & 0.38\% & Similar \\
MediaPipe & 1.51\% & 0.53\% & 42\% more variation \\
\bottomrule
\end{tabular}
\caption{Frame-to-frame stability. MoveNet provides smoothest predictions.}
\end{table}

\textbf{Root cause analysis:} MediaPipe's higher jitter correlates with detection instability -- joints ``flip'' (appear/disappear) between frames 3.2x more often when jitter is high. Right-side joints are particularly unstable (knee: 3.4\%, ankle: 2.8\% flip rate).

\subsection{Detection Completeness}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Model & Full Detection (12/12) & Error with <12 joints & Increase \\
\midrule
\rowcolor{bestcolor}
\textbf{YOLO} & \textbf{87.8\%} & 14.6\% & +15\% \\
MoveNet & 79.2\% & 13.8\% & +27\% \\
MediaPipe & 64.0\% & 15.0\% & +34\% \\
\bottomrule
\end{tabular}
\caption{YOLO detects all joints most reliably. MediaPipe struggles with right-side joints.}
\end{table}

\subsection{Per-Joint Analysis}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Body Region & MediaPipe & MoveNet & YOLO \\
\midrule
Shoulders & 7--8\% & 8--10\% & 8--10\% \\
Elbows & 9\% & 10\% & 10\% \\
Wrists & 9--10\% & 11--12\% & 12--13\% \\
\rowcolor{highlight}
\textbf{Hips} & \textbf{16--17\%} & 10--11\% & 14--15\% \\
Knees & 7--8\% & 6\% & 7--8\% \\
Ankles & 12\% & 10\% & 10\% \\
\bottomrule
\end{tabular}
\caption{Median NMPJPE by body region. MediaPipe shows unusually high hip errors (architecture-specific).}
\end{table}

%==============================================================================
\section{Literature Comparison}
%==============================================================================

\begin{table}[H]
\centering
\small
\begin{tabular}{@{}p{4cm}p{4cm}p{4cm}@{}}
\toprule
\textbf{Paper} & \textbf{What they do} & \textbf{What we add} \\
\midrule
UCO Dataset (Aguilar-Ortega et al., 2023) & 8 models on healthy subjects & MoveNet, real patients, selection strategies \\
\midrule
Baldinger et al. (2025) & OpenPose, 4 discrete angles & 3 mobile models, 0--90° range \\
\midrule
Ullah et al. (2025) & MediaPipe for action scoring & Model comparison, jitter analysis \\
\midrule
Roggio et al. (2024) & Narrative review of HPE & Empirical data on real rehab data \\
\midrule
REHAB24-6 Paper (Cernek et al., 2025) & Dataset paper, RTMPose & MoveNet evaluation, selection comparison \\
\bottomrule
\end{tabular}
\caption{Our work fills gaps in existing literature.}
\end{table}

\textbf{Novel contributions:}
\begin{enumerate}[nosep]
    \item First MoveNet evaluation on rehabilitation data with MoCap ground truth
    \item First systematic comparison of person selection strategies (torso vs bounding box)
    \item First temporal stability analysis for mobile HPE models on clinical data
\end{enumerate}

%==============================================================================
\section{Summary: Model Comparison}
%==============================================================================

\begin{table}[H]
\centering
\begin{tabular}{@{}lcccl@{}}
\toprule
Dimension & MediaPipe & MoveNet & YOLO & Winner \\
\midrule
Accuracy (Median) & 11.2\% & 10.4\% & 11.3\% & $\approx$ (not significant) \\
Rotation Robustness & +31\% & +54\% & +58\% & \textbf{MediaPipe} \\
Multi-Person Robustness & +209\% & +340\% & +274\% & \textbf{MediaPipe} \\
Temporal Stability & 1.51\% & 1.06\% & 1.12\% & \textbf{MoveNet} \\
Detection Rate & 64\% & 79\% & 88\% & \textbf{YOLO} \\
Hip Accuracy & 16--17\% & 10--11\% & 14--15\% & \textbf{MoveNet} \\
Keypoints & 33 & 17 & 17 & \textbf{MediaPipe} \\
\bottomrule
\end{tabular}
\caption{No single model dominates. Trade-offs depend on use case.}
\end{table}

\textbf{Recommendation for home-based rehabilitation:}
\begin{itemize}[nosep]
    \item \textbf{Realistic home environment:} MediaPipe -- more robust to rotation and multi-person
    \item \textbf{Controlled environment:} MoveNet -- slightly better accuracy, more stable
\end{itemize}

%==============================================================================
\section{Proposed Thesis Direction}
%==============================================================================

\textbf{Title:} ``Evaluating Mobile Pose Estimation Models for Home-Based Rehabilitation: Accuracy, Stability, and Robustness''

\textbf{Research Questions:}
\begin{enumerate}[nosep]
    \item How accurate are mobile HPE models on real rehabilitation data?
    \item How stable are predictions over time (temporal stability)?
    \item How robust are models under suboptimal conditions (rotation, multi-person)?
    \item What practical recommendations follow for mobile rehabilitation apps?
\end{enumerate}

\textbf{Contributions:}
\begin{itemize}[nosep]
    \item First MoveNet evaluation on rehabilitation data with MoCap ground truth
    \item First systematic temporal stability analysis for mobile HPE
    \item Quantification of person selection strategies (torso vs bounding box)
    \item Practical guidelines for mobile physiotherapy applications
\end{itemize}

%==============================================================================
\section{Limitations}
%==============================================================================

\begin{itemize}[nosep]
    \item Uneven rotation distribution (41\% frontal, 41\% lateral, 18\% intermediate angles)
    \item Multi-person analysis based on 5 permanent coach videos; ~26 additional videos show sporadic appearances
    \item Single dataset (REHAB24-6) -- generalization to other datasets not tested
\end{itemize}

\end{document}
